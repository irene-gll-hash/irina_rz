## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1000, 6)
- Признаки: 6 числовых
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (1000, 4)
- Признаки: 4 числовых
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, выбросы, шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (1000, 4)
- Признаки: 4 числовых
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, фоновый шум

## 2. Protocol

- Препроцессинг: StandardScaler для всех числовых признаков, SimpleImputer(strategy='median') для пропусков (хотя их не было)
- Поиск гиперпараметров:
  - KMeans: k от 2 до 10
  - DBSCAN: eps от 0.1 до 2.0, min_samples=5 фиксировано
  - Руководствовались silhouette score и PCA визуализацией
- Метрики: silhouette_score, davies_bouldin_score, calinski_harabasz_score. Для DBSCAN метрики считались только на non-noise точках
- Визуализация: PCA(2D) с random_state=42

## 3. Models

Для каждого датасета:
- KMeans: k от 2 до 10, random_state=42, n_init=10
- DBSCAN: eps от 0.1 до 2.0, min_samples=5

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с k=2
- Метрики (silhouette / DB / CH): 0.522 / 0.753 / 2551.2
- Если был DBSCAN: доля шума 3.4%
- Коротко: KMeans лучше из-за сферических кластеров

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.5
- Метрики (silhouette / DB / CH): DBSCAN 0.458 / 0.923 / 815.3, KMeans 0.307 / 1.432 / 532.7
- Если был DBSCAN: доля шума 4.5%
- Коротко: DBSCAN справился с нелинейной структурой

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN с eps=0.3
- Метрики (silhouette / DB / CH): DBSCAN 0.421 / 0.874 / 689.4, KMeans 0.316 / 1.386 / 541.2
- Если был DBSCAN: доля шума 2.2%
- Коротко: DBSCAN отделил плотные ядра от фона

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на нелинейных данных и при разной плотности кластеров, так как ищет сферические кластеры
- DBSCAN выигрывает при произвольной форме кластеров и разной плотности
- Сильнее всего влияло: масштабирование для KMeans, наличие выбросов и разная плотность

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans на датасете B с разными random_state (42, 123, 777, 13, 99)
- Что получилось: средний ARI=0.970, минимальный ARI=0.941
- Вывод: высокая устойчивость благодаря четким кластерам после масштабирования

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры: через средние значения признаков в каждом кластере
- Выводы: кластеры соответствуют скоплениям в пространстве признаков, PCA визуализация подтверждает качество разделения

## 6. Conclusion

1. Масштабирование критически важно для KMeans
2. KMeans работает только со сферическими кластерами одинаковой плотности
3. DBSCAN лучше для нелинейных данных и кластеров разной плотности
4. Метрики для DBSCAN нужно считать только на non-noise точках
5. Визуализация (PCA) помогает оценить качество кластеризации
6. KMeans показывает высокую устойчивость на четких данных

